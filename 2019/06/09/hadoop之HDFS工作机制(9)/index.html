<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hufanglei.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"scrollpercent":true,"onmobile":false},"hljswrap":true,"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="@TOC又到了一堆理论时间了，可是不知道理论，只会无脑复制拷贝代码也太low了吧。关键的是知道全貌，才能更好的完成细节。 一、HDFS 工作机制HDFS的数据流1.HDFS写数据流程①剖析文件写入1）客户端向namenode请求上传文件，namenode检查目标文件是否已存在，父目录是否存在。2）namenode返回是否可以上传。3）客户端请求第一个 block上传到哪几个datanode服务">
<meta property="og:type" content="blog">
<meta property="og:title" content="hadoop之HDFS工作机制(9)">
<meta property="og:url" content="https://hufanglei.github.io/2019/06/09/hadoop%E4%B9%8BHDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6(9)/index.html">
<meta property="og:site_name" content="个人博客">
<meta property="og:description" content="@TOC又到了一堆理论时间了，可是不知道理论，只会无脑复制拷贝代码也太low了吧。关键的是知道全貌，才能更好的完成细节。 一、HDFS 工作机制HDFS的数据流1.HDFS写数据流程①剖析文件写入1）客户端向namenode请求上传文件，namenode检查目标文件是否已存在，父目录是否存在。2）namenode返回是否可以上传。3）客户端请求第一个 block上传到哪几个datanode服务">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/b8a47d140f0da8064ee78fddc551571d_1737628068126.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/a897d33e61a785ecdfc0beb2ecf98f16_1737628068126.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/91e5ef397f9e0db43b18b2b2cdfdd5a7_1737628068126.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/f50ecc8de2103f153ca207fbbd561ade_1737628068126.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/6b1d79b15d19873e69dcdcb88aaf59cc_1737628068126.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/3c5a1d46a8f833d245226f7d9c37bb74_1737628079817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/ef16cc208d1ea2a3466116dbcc49a013_1737628079817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/f1130bb41bf92e37e66ee0872c417f4b_1737628079817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/ab818e8545f0bca5e1b5e5ff40ecb32a_1737628079817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/ef6bdb6b91bf271b8033fbaf9192b45b_1737628079817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/4e7b1a2e7d52b677bf868cf88a75d48d_1737628091505.png">
<meta property="article:published_time" content="2019-06-09T15:23:11.000Z">
<meta property="article:modified_time" content="2025-01-24T03:37:59.000Z">
<meta property="article:author" content="胡方雷">
<meta property="article:tag" content="hadoop hdfs工作机制">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/b8a47d140f0da8064ee78fddc551571d_1737628068126.png">


<link rel="canonical" href="https://hufanglei.github.io/2019/06/09/hadoop%E4%B9%8BHDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6(9)/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hufanglei.github.io/2019/06/09/hadoop%E4%B9%8BHDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6(9)/","path":"2019/06/09/hadoop之HDFS工作机制(9)/","title":"hadoop之HDFS工作机制(9)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>hadoop之HDFS工作机制(9) | 个人博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">个人博客</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">记录生活中的点点滴滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">398</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">105</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">594</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E3%80%81HDFS-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-text">一、HDFS 工作机制</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="nav-text">HDFS的数据流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-text">1.HDFS写数据流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A0%E5%89%96%E6%9E%90%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5"><span class="nav-text">①剖析文件写入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A1%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E6%A6%82%E5%BF%B5"><span class="nav-text">②网络拓扑概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%88%E5%89%AF%E6%9C%AC%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9%EF%BC%89"><span class="nav-text">③机架感知（副本节点选择）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="nav-text">2.HDFS读数据流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E4%B8%80%E8%87%B4%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="nav-text">3.一致性模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-text">二、NameNode工作机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%91%A0NameNode-Secondary-NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-text">①NameNode&amp;Secondary NameNode工作机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%EF%BC%89%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%EF%BC%9Anamenode%E5%90%AF%E5%8A%A8"><span class="nav-text">1）第一阶段：namenode启动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%EF%BC%89%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%EF%BC%9ASecondary-NameNode%E5%B7%A5%E4%BD%9C"><span class="nav-text">2）第二阶段：Secondary NameNode工作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%EF%BC%89chkpoint%E6%A3%80%E6%9F%A5%E6%97%B6%E9%97%B4%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="nav-text">3）chkpoint检查时间参数设置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%91%A1-%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6%E5%92%8C%E7%BC%96%E8%BE%91%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6"><span class="nav-text">② 镜像文件和编辑日志文件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%EF%BC%89%E6%A6%82%E5%BF%B5"><span class="nav-text">1）概念</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#a-Fsimage%E6%96%87%E4%BB%B6%EF%BC%9A"><span class="nav-text">a. Fsimage文件：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#b-Edits%E6%96%87%E4%BB%B6%EF%BC%9A"><span class="nav-text">b. Edits文件：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#c-seen-txid"><span class="nav-text">c. seen_txid</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#d-%E6%AF%8F%E6%AC%A1Namenode%E5%90%AF%E5%8A%A8"><span class="nav-text">d.每次Namenode启动</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#oiv%E6%9F%A5%E7%9C%8Bfsimage%E6%96%87%E4%BB%B6"><span class="nav-text">oiv查看fsimage文件</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Boiv%E5%92%8Coev%E5%91%BD%E4%BB%A4"><span class="nav-text">查看oiv和oev命令</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="nav-text">基本语法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="nav-text">案例实操</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#oev%E6%9F%A5%E7%9C%8Bedits%E6%96%87%E4%BB%B6"><span class="nav-text">oev查看edits文件</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95-1"><span class="nav-text">基本语法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-1"><span class="nav-text">案例实操</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2%E6%BB%9A%E5%8A%A8%E7%BC%96%E8%BE%91%E6%97%A5%E5%BF%97"><span class="nav-text">③滚动编辑日志</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A3namenode%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="nav-text">④namenode版本号</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8Bnamenode%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="nav-text">查看namenode版本号</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#namenode%E7%89%88%E6%9C%AC%E5%8F%B7%E5%85%B7%E4%BD%93%E8%A7%A3%E9%87%8A"><span class="nav-text">namenode版本号具体解释</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A4SecondaryNameNode%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="nav-text">⑤SecondaryNameNode目录结构</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%B8%80"><span class="nav-text">方法一</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E4%BA%8C"><span class="nav-text">方法二</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A5-%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F%E6%93%8D%E4%BD%9C"><span class="nav-text">⑥ 集群安全模式操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-text">概述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95-2"><span class="nav-text">基本语法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B"><span class="nav-text">案例</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A6Namenode%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="nav-text">⑦Namenode多目录配置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-text">三、DataNode工作机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-NameNode-DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-text">1.NameNode &amp; DataNode工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="nav-text">2.数据完整性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%8E%89%E7%BA%BF%E6%97%B6%E9%99%90%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="nav-text">3.掉线时限参数设置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-DataNode%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="nav-text">4.DataNode的目录结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Datanode%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="nav-text">5.Datanode多目录配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81HDFS%E5%85%B6%E4%BB%96%E5%8A%9F%E8%83%BD"><span class="nav-text">四、HDFS其他功能</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E9%9B%86%E7%BE%A4%E9%97%B4%E6%95%B0%E6%8D%AE%E6%8B%B7%E8%B4%9D"><span class="nav-text">1. 集群间数据拷贝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Hadoop%EF%BC%88%E4%B8%8D%E9%80%82%E5%90%88%E5%AD%98%E5%82%A8%E5%B0%8F%E6%96%87%E4%BB%B6%EF%BC%89%E5%AD%98%E6%A1%A3"><span class="nav-text">2.Hadoop（不适合存储小文件）存档</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E5%BF%AB%E7%85%A7%E7%AE%A1%E7%90%86"><span class="nav-text">3.	快照管理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%9B%9E%E6%94%B6%E7%AB%99"><span class="nav-text">4.回收站</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="胡方雷"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">胡方雷</p>
  <div class="site-description" itemprop="description">直到这一刻微笑着说话为止，我至少留下了一公升眼泪</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">594</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">105</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">398</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hufanglei" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hufanglei" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://hufanglei.blog.csdn.net/" title="CSDN → https:&#x2F;&#x2F;hufanglei.blog.csdn.net" rel="noopener me" target="_blank"><i class="crosshairs fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:690328661@qq.com" title="E-Mail → mailto:690328661@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1518938&auto=1&height=66"></iframe>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title">
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="http://www.alloyteam.com/nav/" title="http:&#x2F;&#x2F;www.alloyteam.com&#x2F;nav&#x2F;" rel="noopener" target="_blank">Web前端导航</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="http://www.uisdc.com/" title="http:&#x2F;&#x2F;www.uisdc.com&#x2F;" rel="noopener" target="_blank">优设</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="http://www.zhangxinxu.com/" title="http:&#x2F;&#x2F;www.zhangxinxu.com&#x2F;" rel="noopener" target="_blank">牛人文档</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="http://ife.baidu.com/" title="http:&#x2F;&#x2F;ife.baidu.com&#x2F;" rel="noopener" target="_blank">百度前端技术学院</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="http://wf.uisdc.com/cn/" title="http:&#x2F;&#x2F;wf.uisdc.com&#x2F;cn&#x2F;" rel="noopener" target="_blank">google前端开发基础</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hufanglei.github.io/2019/06/09/hadoop%E4%B9%8BHDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6(9)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="胡方雷">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="个人博客">
      <meta itemprop="description" content="直到这一刻微笑着说话为止，我至少留下了一公升眼泪">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="hadoop之HDFS工作机制(9) | 个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hadoop之HDFS工作机制(9)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-09 23:23:11" itemprop="dateCreated datePublished" datetime="2019-06-09T23:23:11+08:00">2019-06-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-01-24 11:37:59" itemprop="dateModified" datetime="2025-01-24T11:37:59+08:00">2025-01-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>18k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>

<p>@<a href="%E7%9B%AE%E5%BD%95">TOC</a><br>又到了一堆理论时间了，可是不知道理论，只会无脑复制拷贝代码也太low了吧。关键的是知道全貌，才能更好的完成细节。</p>
<h1 id="一、HDFS-工作机制"><a href="#一、HDFS-工作机制" class="headerlink" title="一、HDFS 工作机制"></a>一、HDFS 工作机制</h1><h2 id="HDFS的数据流"><a href="#HDFS的数据流" class="headerlink" title="HDFS的数据流"></a>HDFS的数据流</h2><h3 id="1-HDFS写数据流程"><a href="#1-HDFS写数据流程" class="headerlink" title="1.HDFS写数据流程"></a>1.HDFS写数据流程</h3><h4 id="①剖析文件写入"><a href="#①剖析文件写入" class="headerlink" title="①剖析文件写入"></a>①剖析文件写入</h4><p><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/b8a47d140f0da8064ee78fddc551571d_1737628068126.png" alt="在这里插入图片描述"><br>1）客户端向namenode请求上传文件，namenode检查目标文件是否已存在，父目录是否存在。<br>2）namenode返回是否可以上传。<br>3）客户端请求第一个 block上传到哪几个datanode服务器上。<br>4）namenode返回3个datanode节点，分别为dn1、dn2、dn3。<br>5）客户端请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成<br>6）dn1、dn2、dn3逐级应答客户端<br>7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答<br>8）当一个block传输完成之后，客户端再次请求namenode上传第二个block的服务器。（重复执行3-7步）<br><strong>官网给的源码图分析</strong><br><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/a897d33e61a785ecdfc0beb2ecf98f16_1737628068126.png" alt="在这里插入图片描述"></p>
<ol>
<li><p>   客户端通过调用DistributedFileSystem的create方法创建新文件。</p>
</li>
<li><p>   DistributedFileSystem通过RPC调用namenode去创建一个没有blocks关联的新文件，创建前， namenode会做各种校验，比如文件是否存在，客户端有无权限去创建等。如果校验通过， namenode就会记录下新文件，否则就会抛出IO异常。</p>
</li>
<li><p>   前两步结束后，会返回FSDataOutputStream的对象，与读文件的时候相似， FSDataOutputStream被封装成DFSOutputStream。DFSOutputStream可以协调namenode和 datanode。客户端开始写数据到DFSOutputStream，DFSOutputStream会把数据切成一个个小的packet，然后排成队 列data quene（数据队列）。</p>
</li>
<li><p>   DataStreamer会去处理接受data quene，它先询问namenode这个新的block最适合存储的在哪几个datanode里（比如重复数是3，那么就找到3个最适合的 datanode），把他们排成一个pipeline。DataStreamer把packet按队列输出到管道的第一个datanode中，第一个 datanode又把packet输出到第二个datanode中，以此类推。</p>
</li>
<li><p>   DFSOutputStream还有一个对列叫ack quene，也是由packet组成，等待datanode的收到响应，当pipeline中的所有datanode都表示已经收到的时候，这时ack quene才会把对应的packet包移除掉。 </p>
<blockquote>
<p>如果在写的过程中某个datanode发生错误，会采取以下几步： </p>
<ol>
<li>pipeline被关闭掉；</li>
<li>为了防止防止丢包ack quene里的packet会同步到data quene里；  </li>
<li>把产生错误的datanode上当前在写但未完成的block删掉； </li>
<li>block剩下的部分被写到剩下的两个正常的datanode中； </li>
<li>namenode找到另外的datanode去创建这个块的复制。当然，这些操作对客户端来说是无感知的。</li>
</ol>
</blockquote>
</li>
<li><p>   客户端完成写数据后调用close方法关闭写入流。</p>
</li>
<li><p>   DataStreamer把剩余得包都刷到pipeline里，然后等待ack信息，收到最后一个ack后，通知datanode把文件标视为已完成。</p>
</li>
</ol>
<blockquote>
<p>注意：客户端执行write操作后，写完的block才是可见的(注:和下面的一致性所对应)，正在写的block对客户端是不可见的，只有 调用sync方法，客户端才确保该文件的写操作已经全部完成，当客户端调用close方法时，会默认调用sync方法。是否需要手动调用取决你根据程序需 要在数据健壮性和吞吐率之间的权衡</p>
</blockquote>
<p><em>问题来了?<br>上面的步骤中，namenode会返回给客户一个datanode队列，让客户端请求datanode服务器写数据，namenode咋知道到哪个优先给客户端呢，所以这里涉及到几个名词，看下面的网络拓扑计算规则，和机架感知原理吧，通过这些，才能比较优的写数据</em>.</p>
<h4 id="②网络拓扑概念"><a href="#②网络拓扑概念" class="headerlink" title="②网络拓扑概念"></a>②网络拓扑概念</h4><p>在本地网络中，两个节点被称为“彼此近邻”是什么意思？在海量数据处理中，其主要限制因素是节点之间数据的传输速率——带宽很稀缺。这里的想法是将两个节点间的带宽作为距离的衡量标准。<br>	节点距离：两个节点到达最近的共同祖先的距离总和。<br>例如，假设有数据中心d1机架r1中的节点n1。该节点可以表示为&#x2F;d1&#x2F;r1&#x2F;n1。利用这种标记，这里给出四种距离描述。<br>Distance(&#x2F;d1&#x2F;r1&#x2F;n1, &#x2F;d1&#x2F;r1&#x2F;n1)&#x3D;0（同一节点上的进程）<br>Distance(&#x2F;d1&#x2F;r1&#x2F;n1, &#x2F;d1&#x2F;r1&#x2F;n2)&#x3D;2（同一机架上的不同节点）<br>Distance(&#x2F;d1&#x2F;r1&#x2F;n1, &#x2F;d1&#x2F;r3&#x2F;n2)&#x3D;4（同一数据中心不同机架上的节点）<br>Distance(&#x2F;d1&#x2F;r1&#x2F;n1, &#x2F;d2&#x2F;r4&#x2F;n2)&#x3D;6（不同数据中心的节点）</p>
<p>大家算一算每两个节点之间的距离。<br><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/91e5ef397f9e0db43b18b2b2cdfdd5a7_1737628068126.png" alt="在这里插入图片描述"></p>
<h4 id="③机架感知（副本节点选择）"><a href="#③机架感知（副本节点选择）" class="headerlink" title="③机架感知（副本节点选择）"></a>③机架感知（副本节点选择）</h4><p>1）官方ip地址：<br><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/RackAwareness.html">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/RackAwareness.html</a><br><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication</a><br>2）低版本Hadoop副本节点选择<br>第一个副本在client所处的节点上。如果客户端在集群外，随机选一个。<br>第二个副本和第一个副本位于不相同机架的随机节点上。<br>第三个副本和第二个副本位于相同机架，节点随机。</p>
<p>3）高副本节点选择<br>	第一个副本在client所处的节点上。如果客户端在集群外，随机选一个。<br>	第二个副本和第一个副本位于相同机架，随机节点。<br> <em>第三个副本位于不同机架，随机节点。</em></p>
<h3 id="2-HDFS读数据流程"><a href="#2-HDFS读数据流程" class="headerlink" title="2.HDFS读数据流程"></a>2.HDFS读数据流程</h3><p><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/f50ecc8de2103f153ca207fbbd561ade_1737628068126.png" alt="在这里插入图片描述"><br>1）客户端向namenode请求下载文件，namenode通过查询元数据，找到文件块所在的datanode地址。<br>2）挑选一台datanode（就近原则，然后随机）服务器，请求读取数据。<br>3）datanode开始传输数据给客户端（从磁盘里面读取数据放入流，以packet为单位来做校验）。<br>4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。<br><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/6b1d79b15d19873e69dcdcb88aaf59cc_1737628068126.png" alt="在这里插入图片描述"><br>1.	首先调用FileSystem对象的open方法，其实是一个DistributedFileSystem的实例。<br>2.	DistributedFileSystem通过rpc获得文件的第一批block的locations，同一个block按照重复数会返回多个locations，这些locations按照hadoop拓扑结构排序，距离客户端近的排在前面。<br>3.	前两步会返回一个FSDataInputStream对象，该对象会被封装DFSInputStream对象，DFSInputStream可 以方便的管理datanode和namenode数据流。客户端调用read方法，DFSInputStream最会找出离客户端最近的datanode 并连接。<br>4.	数据从datanode源源不断的流向客户端。<br>5.	如果第一块的数据读完了，就会关闭指向第一块的datanode连接，接着读取下一块。这些操作对客户端来说是透明的，客户端的角度看来只是读一个持续不断的流。<br>6.	如果第一批block都读完了， DFSInputStream就会去namenode拿下一批block的locations，然后继续读，如果所有的块都读完，这时就会关闭掉所有的流。<br>7.	如果在读数据的时候， DFSInputStream和datanode的通讯发生异常，就会尝试正在读的block的排序第二近的datanode,并且会记录哪个 datanode发生错误，剩余的blocks读的时候就会直接跳过该datanode。 DFSInputStream也会检查block数据校验和，如果发现一个坏的block,就会先报告到namenode节点，然后 DFSInputStream在其他的datanode上读该block的镜像。<br>8.	该设计就是客户端直接连接datanode来检索数据并且namenode来负责为每一个block提供最优的datanode， namenode仅仅处理block location的请求，这些信息都加载在namenode的内存中，hdfs通过datanode集群可以承受大量客户端的并发访问。</p>
<h3 id="3-一致性模型"><a href="#3-一致性模型" class="headerlink" title="3.一致性模型"></a>3.一致性模型</h3><p>这是个什么鬼，其实这个类似io的flush，写入数据时，如果希望数据被其他client立即可见，调用如下方法<br>FSDataOutputStream. hflush ();		&#x2F;&#x2F;清理客户端缓冲区数据，被其他client立即可见<br>代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeFile</span><span class="params">()</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">		<span class="comment">// 1 创建配置信息对象</span></span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		fs = FileSystem.get(configuration);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 创建文件输出流</span></span><br><span class="line">		<span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;F:\\output\\word.txt&quot;</span>);</span><br><span class="line">		<span class="type">FSDataOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> fs.create(path);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 写数据</span></span><br><span class="line">		fos.write(<span class="string">&quot;hello Andy&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">// 4 关键代码:一致性刷新</span></span><br><span class="line">		fos.hflush();		</span><br><span class="line">		fos.close();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二、NameNode工作机制"><a href="#二、NameNode工作机制" class="headerlink" title="二、NameNode工作机制"></a>二、NameNode工作机制</h2><h3 id="①NameNode-Secondary-NameNode工作机制"><a href="#①NameNode-Secondary-NameNode工作机制" class="headerlink" title="①NameNode&amp;Secondary NameNode工作机制"></a>①NameNode&amp;Secondary NameNode工作机制</h3><p><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/3c5a1d46a8f833d245226f7d9c37bb74_1737628079817.png" alt="在这里插入图片描述"></p>
<h4 id="1）第一阶段：namenode启动"><a href="#1）第一阶段：namenode启动" class="headerlink" title="1）第一阶段：namenode启动"></a>1）第一阶段：namenode启动</h4><p>（1）第一次启动namenode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志(edits)和镜像文件(fsimage)到内存<br>（2）客户端对元数据进行增删改的请求<br>（3）namenode记录操作日志，更新滚动日志<br>（4）namenode在内存中对数据进行增删改查</p>
<h4 id="2）第二阶段：Secondary-NameNode工作"><a href="#2）第二阶段：Secondary-NameNode工作" class="headerlink" title="2）第二阶段：Secondary NameNode工作"></a>2）第二阶段：Secondary NameNode工作</h4><p>（1）Secondary NameNode询问namenode是否需要checkpoint。直接带回namenode是否检查结果。<br>（2）Secondary NameNode请求执行checkpoint。<br>（3）namenode滚动正在写的edits日志<br>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode<br>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。<br>（6）生成新的镜像文件fsimage.chkpoint<br>（7）拷贝fsimage.chkpoint到namenode<br>（8）namenode将fsimage.chkpoint重新命名成fsimage</p>
<h4 id="3）chkpoint检查时间参数设置"><a href="#3）chkpoint检查时间参数设置" class="headerlink" title="3）chkpoint检查时间参数设置"></a>3）chkpoint检查时间参数设置</h4><ul>
<li>1&gt;通常情况下，SecondaryNameNode每隔一小时执行一次<br>hdfs-default.xml</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="number">3600</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>2&gt;一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="number">1000000</span>&lt;/value&gt;</span><br><span class="line">&lt;description&gt;操作动作次数&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;<span class="number">60</span>&lt;/value&gt;</span><br><span class="line">&lt;description&gt; <span class="number">1</span>分钟检查一次操作次数&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="②-镜像文件和编辑日志文件"><a href="#②-镜像文件和编辑日志文件" class="headerlink" title="② 镜像文件和编辑日志文件"></a>② 镜像文件和编辑日志文件</h3><h4 id="1）概念"><a href="#1）概念" class="headerlink" title="1）概念"></a>1）概念</h4><p>amenode被格式化之后，将在&#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name&#x2F;current目录中产生如下文件,注只能在NameNode所在的节点才能找到此文件<br>可以执行find . -name edits* 来查找文件</p>
<pre><code>edits_0000000000000000000
fsimage_0000000000000000000.md5
seen_txid
VERSION
</code></pre>
<h5 id="a-Fsimage文件："><a href="#a-Fsimage文件：" class="headerlink" title="a. Fsimage文件："></a>a. Fsimage文件：</h5><p>HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件idnode的序列化信息。 </p>
<h5 id="b-Edits文件："><a href="#b-Edits文件：" class="headerlink" title="b. Edits文件："></a>b. Edits文件：</h5><p>存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到edits文件中。 </p>
<h5 id="c-seen-txid"><a href="#c-seen-txid" class="headerlink" title="c. seen_txid"></a>c. seen_txid</h5><p>文件保存的是一个数字，就是最后一个edits_的数字,文件被操作的次数。</p>
<h5 id="d-每次Namenode启动"><a href="#d-每次Namenode启动" class="headerlink" title="d.每次Namenode启动"></a>d.每次Namenode启动</h5><p>每次Namenode启动的时候都会将fsimage文件读入内存，并从00001开始到seen_txid中记录的数字依次执行每个edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成Namenode启动的时候就将fsimage和edits文件进行了合并。</p>
<h4 id="oiv查看fsimage文件"><a href="#oiv查看fsimage文件" class="headerlink" title="oiv查看fsimage文件"></a>oiv查看fsimage文件</h4><h5 id="查看oiv和oev命令"><a href="#查看oiv和oev命令" class="headerlink" title="查看oiv和oev命令"></a>查看oiv和oev命令</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 current]$ hdfs</span><br><span class="line">oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">oev                  apply the offline edits viewer to an edits file</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h5><p>hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径</p>
<h5 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 current]$ pwd</span><br><span class="line">/opt/module/hadoop-2.8.4/data/dfs/name/current</span><br><span class="line">[root@bigdata111 current]$ hdfs oiv -p XML -i fsimage_0000000000000000316 -o /opt/fsimage.xml</span><br><span class="line">[root@bigdata111 current]$ cat /opt/module/hadop-2.8.4/fsimage.xml</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>将显示的xml文件内容拷贝到IDEA中创建的xml文件中，并格式化。</p>
<h4 id="oev查看edits文件"><a href="#oev查看edits文件" class="headerlink" title="oev查看edits文件"></a>oev查看edits文件</h4><h5 id="基本语法-1"><a href="#基本语法-1" class="headerlink" title="基本语法"></a>基本语法</h5><p>hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径</p>
<blockquote>
<p><strong>-p</strong>	–processor <arg>   指定转换类型: binary (二进制格式), xml (默认，XML格式),stats<br><strong>-i</strong>	–inputFile <arg>     输入edits文件，如果是xml后缀，表示XML格式，其他表示二进制<br><strong>-o</strong> 	–outputFile <arg> 输出文件，如果存在，则会覆盖</p>
</blockquote>
<h5 id="案例实操-1"><a href="#案例实操-1" class="headerlink" title="案例实操"></a>案例实操</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 current]$ hdfs oev -p XML -i edits_0000000000000000135-0000000000000000135 -o /opt/module/hadoop-2.8.4/edits.xml -p stats</span><br><span class="line">[itstar@bigdata111 current]$ cat /opt/module/hadoop-2.8.4/edits.xml</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/ef16cc208d1ea2a3466116dbcc49a013_1737628079817.png" alt="在这里插入图片描述"><br>每个RECORD记录了一次操作，比如图中的<br>OP_ADD代表添加文件操作、OP_MKDIR代表创建目录操作。里面还记录了<br>文件路径（PATH）<br>修改时间（MTIME）<br>添加时间（ATIME）<br>客户端名称（CLIENT_NAME）<br>客户端地址（CLIENT_MACHINE）<br>权限（PERMISSION_STATUS）等非常有用的信息</p>
<p><em><strong>将显示的xml文件内容拷贝到IDEA中创建的xml文件中，并格式化。</strong></em></p>
<h4 id="③滚动编辑日志"><a href="#③滚动编辑日志" class="headerlink" title="③滚动编辑日志"></a>③滚动编辑日志</h4><p>正常情况HDFS文件系统有更新操作时，就会滚动编辑日志。也可以用命令强制滚动编辑日志。<br>1）滚动编辑日志（前提必须启动集群）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 current]$ hdfs dfsadmin -rollEdits</span><br><span class="line"></span><br><span class="line">举例：原文件名edits_inprogress_0000000000000000321</span><br><span class="line">执行以下命令后</span><br><span class="line">[root@bigdata111 current]# hdfs dfsadmin -rollEdits</span><br><span class="line">Successfully rolled edit logs.</span><br><span class="line">New segment starts at txid 323</span><br><span class="line">edits_inprogress_0000000000000000321 =&gt; edits_inprogress_0000000000000000323</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2）镜像文件什么时候产生<br>Namenode启动时加载镜像文件和编辑日志</p>
<h4 id="④namenode版本号"><a href="#④namenode版本号" class="headerlink" title="④namenode版本号"></a>④namenode版本号</h4><h5 id="查看namenode版本号"><a href="#查看namenode版本号" class="headerlink" title="查看namenode版本号"></a>查看namenode版本号</h5><p>在&#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name&#x2F;current这个目录下查看VERSION</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">namespaceID=1778616660</span><br><span class="line">clusterID=CID-bc165781-d10a-46b2-9b6f-3beb1d988fe0</span><br><span class="line">cTime=1552918200296</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-274621862-192.168.1.111-1552918200296</span><br><span class="line">layoutVersion=-63</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="namenode版本号具体解释"><a href="#namenode版本号具体解释" class="headerlink" title="namenode版本号具体解释"></a>namenode版本号具体解释</h5><blockquote>
<p>（1） namespaceID在HDFS上，会有多个Namenode，所以不同Namenode的namespaceID是不同的，分别管理一组blockpoolID。<br>（2）clusterID集群id，全局唯一<br>（3）cTime属性标记了namenode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。<br>（4）storageType属性说明该存储目录包含的是namenode的数据结构。<br>（5）blockpoolID：一个block pool id标识一个block pool，并且是跨集群的全局唯一。当一个新的Namespace被创建的时候(format过程的一部分)会创建并持久化一个唯一ID。在创建过程构建全局唯一的BlockPoolID比人为的配置更可靠一些。NN将BlockPoolID持久化到磁盘中，在后续的启动过程中，会再次load并使用。<br>（6）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。<br>（7）storageID (存储ID)：是DataNode的ID,不唯一</p>
</blockquote>
<h4 id="⑤SecondaryNameNode目录结构"><a href="#⑤SecondaryNameNode目录结构" class="headerlink" title="⑤SecondaryNameNode目录结构"></a>⑤SecondaryNameNode目录结构</h4><p>Secondary NameNode用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。<br>在&#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;namesecondary&#x2F;current这个目录中查看SecondaryNameNode目录结构。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">edits_0000000000000000001-0000000000000000002</span><br><span class="line">fsimage_0000000000000000002</span><br><span class="line">fsimage_0000000000000000002.md5</span><br><span class="line">VERSION</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>SecondaryNameNode的namesecondary&#x2F;current目录和主namenode的current目录的布局相同。</p>
<blockquote>
<p><strong>好处</strong>：在主namenode发生故障时（假设没有及时备份数据），可以从SecondaryNameNode恢复数据。</p>
</blockquote>
<h5 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h5><p>将SecondaryNameNode中数据拷贝到namenode存储数据的目录；</p>
<h5 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h5><p>使用-importCheckpoint选项启动namenode守护进程，从而将SecondaryNameNode中数据拷贝到namenode目录中.</p>
<ul>
<li>案例实操（一）<br>模拟namenode故障，并采用方法一，恢复namenode数据:<blockquote>
<p>（1）kill -9 namenode进程<br>（2）删除namenode存储的数据（&#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name）<br>rm -rf &#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name&#x2F;*		<br>      注：此时hadoop-daemon.sh stop namenode关闭NN,<br>      然后hadoop-daemon.sh start namenode重启NN,发现50070页面启动不了</p>
</blockquote>
</li>
</ul>
<p>（3）拷贝SecondaryNameNode中数据到原namenode存储数据目录<br>		cp -r &#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;namesecondary&#x2F;* &#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name&#x2F;<br>（4）重新启动namenode<br>sbin&#x2F;hadoop-daemon.sh start namenode</p>
<ul>
<li>案例实操（二）<br>模拟namenode故障，并采用方法二，恢复namenode数据<br>（0）修改hdfs-site.xml中的配置，value的单位是秒，默认3600，即1小时，仅配置一台即可</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;120&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/opt/mod/hadoop-2.8.4/data/dfs/name&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>（1）kill -9 namenode进程<br>（2）删除namenode存储的数据（&#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name）<br>rm -rf &#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;name&#x2F;*<br>（3）如果SecondaryNameNode不和Namenode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到Namenode存储数据的平级目录。</p>
</blockquote>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">bigdata111</span> <span class="type">dfs</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line"> /opt/mod/hadoop<span class="literal">-2</span>.<span class="number">8.4</span>/<span class="keyword">data</span>/dfs</span><br><span class="line">[<span class="type">root</span>@<span class="type">bigdata111</span> <span class="type">dfs</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line"><span class="keyword">data</span>  name  namesecondary</span><br></pre></td></tr></table></figure>
<blockquote>
<p>（4）导入检查点数据（等待一会ctrl+c结束掉）<br>bin&#x2F;hdfs namenode -importCheckpoint<br>（5）启动namenode<br>sbin&#x2F;hadoop-daemon.sh start namenode<br>（6）如果提示文件锁了，可以删除in_use.lock<br>		rm -rf &#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;namesecondary&#x2F;in_use.lock</p>
</blockquote>
<h4 id="⑥-集群安全模式操作"><a href="#⑥-集群安全模式操作" class="headerlink" title="⑥ 集群安全模式操作"></a>⑥ 集群安全模式操作</h4><h5 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h5><p>amenode启动时，首先将映像文件（fsimage）载入内存，并执行编辑日志（edits）中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的fsimage文件和一个空的编辑日志。此时，namenode开始监听datanode请求。但是此刻，namenode运行在安全模式，即namenode的文件系统对于客户端来说是只读的。<br>系统中的数据块的位置并不是由namenode维护的，而是以块列表的形式存储在datanode中。在系统的正常操作期间，namenode会在内存中保留所有块位置的映射信息。在安全模式下，各个datanode会向namenode发送最新的块列表信息，namenode了解到足够多的块位置信息之后，即可高效运行文件系统。<br>如果满足“最小副本条件”，namenode会在30秒钟之后就退出安全模式。所谓的最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别（默认值：dfs.replication.min&#x3D;1）。在启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以namenode不会进入安全模式。</p>
<h5 id="基本语法-2"><a href="#基本语法-2" class="headerlink" title="基本语法"></a>基本语法</h5><p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">（1）bin/hdfs dfsadmin -safemode get		（功能描述：查看安全模式状态）</span><br><span class="line">（2）bin/hdfs dfsadmin -safemode enter  	（功能描述：进入安全模式状态）</span><br><span class="line">（3）bin/hdfs dfsadmin -safemode leave	（功能描述：离开安全模式状态）</span><br><span class="line">（4）bin/hdfs dfsadmin -safemode wait	（功能描述：等待安全模式状态）</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h5><blockquote>
<p>模拟等待安全模式<br>1）先进入安全模式<br>bin&#x2F;hdfs dfsadmin -safemode enter<br>	2）执行下面的脚本<br>编辑一个脚本(注：必须已设置环境变量，要不就写绝对路径)</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!bin/bash</span></span><br><span class="line">hdfs dfsadmin -safemode wait</span><br><span class="line">hadoop fs -put /opt/BBB /</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>3）再打开一个窗口，执行<br>bin&#x2F;hdfs dfsadmin -safemode leave</p>
</blockquote>
<h4 id="⑦Namenode多目录配置"><a href="#⑦Namenode多目录配置" class="headerlink" title="⑦Namenode多目录配置"></a>⑦Namenode多目录配置</h4><ul>
<li>1）namenode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性。</li>
<li>2）具体配置如下：<br>  hdfs-site.xml</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/name1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/name2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<ol>
<li>   停止集群 删除data 和 logs  rm -rf data&#x2F;* logs&#x2F;*</li>
<li>   hdfs namenode -format</li>
<li>   start-dfs.sh</li>
<li>   去展示<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39657909/article/details/85553525">https://blog.csdn.net/qq_39657909/article/details/85553525</a></li>
</ol>
</blockquote>
<p><strong>实验总结</strong></p>
<blockquote>
<p>思考1：如果在非Namenode节点、进行格式化(hdfs namenode -format)<br>是否和在NN节点上同样会生成name1和name2目录呢？</p>
</blockquote>
<p> 答：只要配置了以上得配置，在该节点下同样会生成name1和name2<br>具体解释：<br>格式化做了哪些事情？<br>在NameNode节点上，有两个最重要的路径，分别被用来存储元数据信息和操作日志，而这两个路径来自于配置文件，它们对应的属性分别是dfs.name.dir和dfs.name.edits.dir，同时，它们默认的路径均是&#x2F;tmp&#x2F;hadoop&#x2F;dfs&#x2F;name。格式化时，NameNode会清空两个目录下的所有文件，之后，格式化会在目录dfs.name.dir下创建文件<br>hadoop.tmp.dir 这个配置，会让dfs.name.dir和dfs.name.edits.dir会让两个目录的文件生成在一个目录里</p>
<blockquote>
<p>思考2：非NN上如果生成了name1和name2，那么他和NN上生成得有没有差别？</p>
</blockquote>
<p>答：有区别、NN节点上会产生新得edits_XXX，非NN不会fsimage会更新，而非NN不会，只会产生一个仅初始化得到得fsimage，不会生成edits,更不会发生日志滚动。</p>
<h2 id="三、DataNode工作机制"><a href="#三、DataNode工作机制" class="headerlink" title="三、DataNode工作机制"></a>三、DataNode工作机制</h2><h3 id="1-NameNode-DataNode工作机制"><a href="#1-NameNode-DataNode工作机制" class="headerlink" title="1.NameNode &amp; DataNode工作机制"></a>1.NameNode &amp; DataNode工作机制</h3><p><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/f1130bb41bf92e37e66ee0872c417f4b_1737628079817.png" alt="在这里插入图片描述"></p>
<blockquote>
<p>1）一个数据块在datanode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。<br>2）DataNode启动后向namenode注册，通过后，周期性（1小时）的向namenode上报所有的块信息。<br>3）心跳是每3秒一次，心跳返回结果带有namenode给该datanode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个datanode的心跳，则认为该节点不可用。<br>4）集群运行中可以安全加入和退出一些机器</p>
</blockquote>
<h3 id="2-数据完整性"><a href="#2-数据完整性" class="headerlink" title="2.数据完整性"></a>2.数据完整性</h3><p>1）当DataNode读取block的时候，它会计算checksum校验和<br>2）如果计算后的checksum，与block创建时值不一样，说明block已经损坏。<br>3）client读取其他DataNode上的block.<br>4）datanode在其文件创建后周期验证checksum校验和</p>
<h3 id="3-掉线时限参数设置"><a href="#3-掉线时限参数设置" class="headerlink" title="3.掉线时限参数设置"></a>3.掉线时限参数设置</h3><blockquote>
<p>datanode进程死亡或者网络故障造成datanode无法与namenode通信，namenode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。HDFS默认的超时时长为10分钟+30秒。如果定义超时时间为timeout，则超时时长的计算公式为：<br>timeout  &#x3D; 2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval。<br>而默认的dfs.namenode.heartbeat.recheck-interval 大小为5分钟，dfs.heartbeat.interval默认为3秒。<br>需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;300000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt; dfs.heartbeat.interval &lt;/name&gt;</span><br><span class="line">    &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="4-DataNode的目录结构"><a href="#4-DataNode的目录结构" class="headerlink" title="4.DataNode的目录结构"></a>4.DataNode的目录结构</h4><p>和namenode不同的是，datanode的存储目录是初始阶段自动创建的，不需要额外格式化。</p>
<ul>
<li>1）在&#x2F;opt&#x2F;mod&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;data&#x2F;current这个目录下查看版本号</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[itstar@bigdata111 current]$ cat VERSION </span><br><span class="line">storageID=DS-1b998a1d-71a3-43d5-82dc-c0ff3294921b</span><br><span class="line">clusterID=CID-1f2bf8d1-5ad2-4202-af1c-6713ab381175</span><br><span class="line">cTime=0</span><br><span class="line">datanodeUuid=970b2daf-63b8-4e17-a514-d81741392165</span><br><span class="line">storageType=DATA_NODE</span><br><span class="line">layoutVersion=-56</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>2）具体解释<br>（1）storageID：存储id号<br>  （2）clusterID集群id，全局唯一<br>  （3）cTime属性标记了datanode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。<br>  （4）datanodeUuid：datanode的唯一识别码<br>  （5）storageType：存储类型<br>  （6）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。</p>
</li>
<li><p>3）在&#x2F;opt&#x2F;module&#x2F;hadoop-2.8.4&#x2F;data&#x2F;dfs&#x2F;data&#x2F;current&#x2F;BP-97847618-192.168.10.102-1493726072779&#x2F;current这个目录下查看该数据块的版本号</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata111 current]$ cat VERSION </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Mon May 08 16:30:19 CST 2017</span></span><br><span class="line">namespaceID=1933630176</span><br><span class="line">cTime=0</span><br><span class="line">blockpoolID=BP-97847618-192.168.10.102-1493726072779</span><br><span class="line">layoutVersion=-56</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>4）具体解释<br>（1）namespaceID：是datanode首次访问namenode的时候从namenode处获取的storageID对每个datanode来说是唯一的（但对于单个datanode中所有存储目录来说则是相同的），namenode可用这个属性来区分不同datanode。<br>（2）cTime属性标记了datanode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。<br>（3）blockpoolID：一个block pool id标识一个block pool，并且是跨集群的全局唯一。当一个新的Namespace被创建的时候(format过程的一部分)会创建并持久化一个唯一ID。在创建过程构建全局唯一的BlockPoolID比人为的配置更可靠一些。NN将BlockPoolID持久化到磁盘中，在后续的启动过程中，会再次load并使用。<br>（4）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。</li>
</ul>
<h3 id="5-Datanode多目录配置"><a href="#5-Datanode多目录配置" class="headerlink" title="5.Datanode多目录配置"></a>5.Datanode多目录配置</h3><p>1）datanode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本。<br>2）具体配置如下：<br>	hdfs-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/data2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="四、HDFS其他功能"><a href="#四、HDFS其他功能" class="headerlink" title="四、HDFS其他功能"></a>四、HDFS其他功能</h2><h3 id="1-集群间数据拷贝"><a href="#1-集群间数据拷贝" class="headerlink" title="1. 集群间数据拷贝"></a>1. 集群间数据拷贝</h3><ul>
<li>1）scp实现两个远程主机之间的文件复制</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r hello.txt root@bigdata111:/user/hfl/hello.txt		// 推 push</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r root@bigdata112:/user/hfl/hello.txt  hello.txt		// 拉 pull</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scp -r root@bigdata112:/opt/mod/hadoop-2.8.4/LICENSE.txt </span><br><span class="line">root@bigdata113:/opt/module/hadoop-2.8.4/LICENSE.txt   </span><br><span class="line">//是通过本地主机中转实现两个远程主机的文件复制；</span><br><span class="line">//如果在两个远程主机之间ssh没有配置的情况下可以使用该方式</span><br></pre></td></tr></table></figure>
<ul>
<li>2）采用discp命令实现两个hadoop集群之间的递归数据复制(注:不用设置其他，直接写IP)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop distcp hdfs://192.168.1.51:9000/LICENSE.txt hdfs://192.168.1.111:9000/HAHA</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-Hadoop（不适合存储小文件）存档"><a href="#2-Hadoop（不适合存储小文件）存档" class="headerlink" title="2.Hadoop（不适合存储小文件）存档"></a>2.Hadoop（不适合存储小文件）存档</h3><ul>
<li><p>1）理论概述<br>每个文件均按块存储，每个块的元数据存储在namenode的内存中，因此hadoop存储小文件会非常低效。因为大量的小文件会耗尽namenode中的大部分内存。但注意，存储小文件所需要的磁盘容量和存储这些文件原始内容所需要的磁盘空间相比也不会增多。例如，一个1MB的文件以大小为128MB的块存储，使用的是1MB的磁盘空间，而不是128MB。<br>Hadoop存档文件或HAR文件，是一个更高效的文件存档工具，它将文件存入HDFS块，在减少namenode内存使用的同时，允许对文件进行透明的访问。具体说来，Hadoop存档文件可以用作MapReduce的输入。<br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/staryea/p/8603112.html">https://www.cnblogs.com/staryea/p/8603112.html</a></p>
</li>
<li><p>2)案例实操</p>
<blockquote>
<p>（1）需要启动yarn进程<br>  start-yarn.sh<br>（2）归档文件<br>  归档成一个叫做xxx.har的文件夹，该文件夹下有相应的数据文件。Xx.har目录是一个整体，该目录看成是一个归档文件即可。<br><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/ab818e8545f0bca5e1b5e5ff40ecb32a_1737628079817.png" alt="在这里插入图片描述"><br><em><strong>用法：hadoop archive -archiveName  归档名称 -p 父目录 [-r &lt;复制因子&gt;]  原路径（可以多个）  目的路径</strong></em></p>
</blockquote>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/ hadoop archive -archiveName foo.har -p /Andy -r 3 a b c /</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>（3）查看归档<br>hadoop fs -lsr &#x2F;user&#x2F;root&#x2F;myhar.har<br>hadoop fs -lsr har:&#x2F;&#x2F;&#x2F;myhar.har<br><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/ef6bdb6b91bf271b8033fbaf9192b45b_1737628079817.png" alt="在这里插入图片描述"></p>
</blockquote>
<blockquote>
<p>（4）解归档文件<br>取消存档：hadoop fs -cp har:&#x2F;&#x2F;&#x2F; user&#x2F;my&#x2F;myhar.har &#x2F;* &#x2F;user&#x2F;itstar<br>并行解压缩：hadoop distcp har:&#x2F;foo.har &#x2F;001</p>
</blockquote>
<h3 id="3-快照管理"><a href="#3-快照管理" class="headerlink" title="3.	快照管理"></a>3.	快照管理</h3><p>快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。</p>
<ul>
<li>1）基本语法<blockquote>
<p>（1）hdfs dfsadmin -allowSnapshot 路径   （功能描述：开启指定目录的快照功能）<br>  （2）hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）<br>  （3）hdfs dfs -createSnapshot 路径        （功能描述：对目录创建快照）<br>  （4）hdfs dfs -createSnapshot 路径 名称   （功能描述：指定名称创建快照）<br>  （5）hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）<br>  （6）hdfs lsSnapshottableDir         （功能描述：列出当前用户所有已快照目录）<br>  （7）hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）<br>  （8）hdfs dfs -deleteSnapshot <path> <snapshotName>  （功能描述：删除快照）</p>
</blockquote>
</li>
<li>2）案例实操<br>（1）开启&#x2F;禁用指定目录的快照功能</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -allowSnapshot /user/itstar/data		</span><br><span class="line">hdfs dfsadmin -disallowSnapshot /user/itstar/data	</span><br></pre></td></tr></table></figure>
<pre><code>（2）对目录创建快照
</code></pre>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -createSnapshot /user/hfl/data		// 对目录创建快照</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>用相同数据块</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">hdfs</span> dfs -<span class="keyword">lsr</span> /user/hfl/<span class="meta">data</span>/.snapshot/</span><br></pre></td></tr></table></figure>
<p>（3）指定名称创建快照<br><code>hdfs dfs -createSnapshot /user/itstar/data miao170508		 </code><br>（4）重命名快照（注：快照是只读的，无法修改名） 快照的目录 老快照的名字 新快照的名字</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -renameSnapshot /Andy/ andy bndy		</span><br></pre></td></tr></table></figure>

<p>注：路径只是你创建得名字&#x2F;Andy，不要带后边得&#x2F;Andy&#x2F;.snapshot&#x2F;，不然会出现<br>renameSnapshot: Modification on a read-only snapshot is disallowed<br>	（5）列出当前用户所有可快照目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs lsSnapshottableDir	</span><br></pre></td></tr></table></figure>

<p>（6）比较两个快照目录的不同之处<br>               快照的名字    之前的快照名字  新快照的名字</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs snapshotDiff /user/hfl/data/  hfl hfl1</span><br></pre></td></tr></table></figure>
<p>（7）恢复快照<br>1.	自定义创建一个快照名：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -createSnapshot /HAHA1 miaomiao</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>   展示原文件包含内容：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /HAHA1</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>   里面有五个文件、删除其中1~2个</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/HAHA1/.snapshot/miaomiao1</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>   恢复快照：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cp /HAHA1/.snapshot/miaomiao1 /miaomiao</span><br></pre></td></tr></table></figure>

<p>（8）删除快照</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -deleteSnapshot /001名字</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="4-回收站"><a href="#4-回收站" class="headerlink" title="4.回收站"></a>4.回收站</h3><ul>
<li>1）默认回收站<br>默认值fs.trash.interval&#x3D;0，0表示禁用回收站，可以设置删除文件的存活时间。<br>默认值fs.trash.checkpoint.interval&#x3D;0，检查回收站的间隔时间。<br>要求fs.trash.checkpoint.interval&lt;&#x3D;fs.trash.interval。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/hufanglei/img-csdn/main/img/2025-1-13/4e7b1a2e7d52b677bf868cf88a75d48d_1737628091505.png" alt="在这里插入图片描述"></p>
<ul>
<li>2）启用回收站<br>修改core-site.xml，配置垃圾回收时间为1分钟。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p>3）查看回收站<br>回收站在集群中的；路径：&#x2F;user&#x2F;hfl&#x2F;.Trash&#x2F;….</p>
</li>
<li><p>4）修改访问垃圾回收站用户名称<br>进入垃圾回收站用户名称，默认是dr.who，修改为root用户<br>core-site.xml</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>5）通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Trash</span> <span class="variable">trash</span> <span class="operator">=</span> New <span class="title function_">Trash</span><span class="params">(conf)</span>;</span><br><span class="line">trash.moveToTrash(path);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>6）恢复回收站数据</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv /user/hfl/.Trash/Current/user/hfl/input    /user/hfl/input</span><br></pre></td></tr></table></figure>
<ul>
<li>7）清空回收站</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -expunge</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>胡方雷
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://hufanglei.github.io/2019/06/09/hadoop%E4%B9%8BHDFS%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6(9)/" title="hadoop之HDFS工作机制(9)">https://hufanglei.github.io/2019/06/09/hadoop之HDFS工作机制(9)/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/hadoop-hdfs%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/" rel="tag"># hadoop hdfs工作机制</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/06/09/hadoop%E4%B9%8B%E6%93%8D%E4%BD%9Cwindow%E4%B8%8BHDFS%20API%E7%BC%96%E7%A8%8B(8)/" rel="prev" title="hadoop之操作window下HDFS API编程(8)">
                  <i class="fa fa-angle-left"></i> hadoop之操作window下HDFS API编程(8)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2019/06/10/hadoop%E4%B9%8Bmapreduce%E7%9A%84wordcount%E7%A8%8B%E5%BA%8F(10)/" rel="next" title="hadoop之mapreduce的wordcount程序(10)">
                  hadoop之mapreduce的wordcount程序(10) <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">胡方雷</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">1.8m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">26:40</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/hufanglei" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
